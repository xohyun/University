---
title: "Datamining-hw2"
author : "01조"
date : "2020.9.29"
output: html_document
---


## library load
```{r library}
# library load
library(ISLR)
library(class)
```


## ch3) 9.

### (a)
```{r}
###Q)모든 변수에 대한 plot
#sol)
data(Auto)
pairs(Auto)
```

### (b)
```{r}
###Q)name 질적변수를 제외한 변수들의 correlation
#sol)
cor(Auto[1:8])
```

### (c)
```{r}
###Q)반응변수 mpg ~ 예측변수 .-name 에 대한 multiple linear regression
#sol)
auto_lm <- lm(mpg ~ .-name, data = Auto)
summary(auto_lm)
# i.
# mpg와 displacement, weight, year, origin은 관계가 존재한다고 볼 수 있다.(연관성이 있는 것 같다.) Adjusted R-squared 값은 81.82% 만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값은 2.2e-16보다 작으므로 유의수준 0.05보다 작기에 이 회귀식은 회귀분석 모델 전체에 대해 통계적으로 의미가 있다고 볼 수 있다. 하지만 모든 변수가 유의하지는 않다.

# ii.
# Coefficients에 나온 변수들의 p-value값을 보면 displacement, weight, year, origin는 유의수준 0.05보다 작기에 회귀식을 설명하는데 유의하다고 판단할 수 있다.

# iii.
# year의 coefficient는 0.750773으로 추정된다. 다른 변수들의 값이 고정된 상태에서 year 변수값이 한 단위 증가 할수록, mpg가 0.750773 만큼 증가한다고 볼 수 있다.

```

### (d)
```{r}
###Q) diagnostic plots of the linear regression fit
#sol)
par(mfrow = c(2,2))
plot(auto_lm)

# Residuals vs Fitted 그림을 보면, 323, 326, 327 관측치가 outlier로 보인다.
# Normal Q-Q 그림을 보면, 323. 326. 327 관측치를 제외하면 정규성을 만족하는 것으로 보인다.
# Residuals vs Leverage 그림을 보면, 14는 high leverage&outlier, 327, 394는 outlier로 판단된다.

par(mfrow = c(1,2))
#예측값과 실제값 겹쳐그리기
plot(predict(auto_lm),type='l',col='red')
par(new=T)
points(Auto$mpg,type='l',col='blue')

#잔차그래프 그리기
plot(auto_lm$residuals,type='l',col='green')

#잔차그래프를 주로 참조했을 때, 잔차들이 평균적으로 0에는 몰려있는 것 같으나, 이상점으로 보이는 극단적으로 큰 혹은 작은 값들이 보인다. 즉, 잔차의 분산이 큰 것으로 판단된다.
```

### (e)
```{r}
###Q) interactoin effects
#sol)
# 두 가지의 분석을 해보았다.
# (i)
# (d)에서 살펴본 유의하지 않은 변수들을 이용하여 유의하다고 판단했던 변수들의 교호작용을 살펴보자.

fit1 <- lm(mpg ~ horsepower + acceleration + cylinders * displacement + displacement * origin + displacement * year + displacement * weight, data = Auto)
summary(fit1)
# Adjusted R-squared 86.7%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하다고 볼 수 있지만, cylinders와 displacement의 교호작용과 displacement와 origin의 교호작용이 유의하지 않으므로 이것을 뺴고 회귀분석을 해보았다.

fit2 <- lm(mpg ~ horsepower + acceleration + displacement * year + displacement * weight, data = Auto)
summary(fit2)
# Adjusted R-squared 86.44%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하다고 볼 수 있지만, acceleration이 유의하지 않으므로 이것을 뺴고 회귀분석을 해보았다.

fit3 <- lm(mpg ~ horsepower + displacement * year + displacement * weight, data = Auto)
summary(fit3)
# Adjusted R-squared 86.45%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하고, 모든 변수와 교호작용 또한 유의하므로 적절한 모형이라고 판단할 수 있다.

#(ii)
#(b)에서 본 상관계수 행렬을 참조하여, displacement와 weight 변수의 교호작용이 있을 거라 생각. 이에 대한 교호작용을 넣어보았다.
my_fit1<-lm(mpg~.-name+displacement:weight,data=Auto)
summary(my_fit1)
#displacement:weight 회귀계수가 유의하다 판단.(p-value가 매우 작음.) 하지만 cylinders와 acceleration이 유의하지 않으므로 둘을 빼고 회귀분석을 해 보았다.

my_fit2<-lm(mpg~.-name-cylinders-acceleration+displacement:weight,data=Auto)
summary(my_fit2)
# Adjusted R-squared 85.63%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하고, 모든 변수와 교호작용 또한 유의하므로 적절한 모형이라고 판단할 수 있다.


# (i)과 (ii)의 두 개의 모델을 보았을 때, displacement와 year의 교호작용을 제외하면 다른 변수들은 같은 것을 알 수 있다. Adjusted R-squared는 (i)는 0.8645, (ii)는 0.8563으로 두 번째 모형이 더 적은 교호작용 term으로 첫 번째 모형과 비슷한 결정계수값을 보이므로 더 나은 모형이라고 생각하였다.
```


### (f)
```{r}
###Q) 변수변환
#sol)
summary(Auto)
#displacement, horsepower, weight 변수의 최댓값, 최솟값 차이가 상대적으로 다른 변수보다 큰 것으로 판단하여 displacement, horsepower, weight 변수에 log, 루트, 제곱 변환을 취해 보았다.

par(mfrow = c(2,2))

#displace
plot(Auto$displacement, Auto$mpg)
plot(log(Auto$displacement), Auto$mpg)
abline(lm(mpg ~ log(displacement), data = Auto), lty = 1, col = "red")
plot(sqrt(Auto$displacement), Auto$mpg)
abline(lm(mpg ~ sqrt(displacement), data = Auto), lty = 1, col = "red")
plot((Auto$displacement)^2, Auto$mpg)
# 그려진 plot들을 보면, displacement는 로그 변환을 취하는 것이 좋아보인다.

trans_lm1<-lm(mpg~.-name-displacement+log(displacement),data=Auto)
#원 displacement 변수의 회귀계수 유의확률보다 작은 것을 확인할 수 있다.
#따라서, displacement 변수에 log값을 취해보는 것도 고려해 볼만 하다 사려된다.

summary(trans_lm1)
# Adjusted R-squared 82.15%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하지만, acceleration과 cylinders 변수는 유의하지 않아보인다.

#제곱근 변환에 대한 회귀분석도 해보았다.
trans_lm2<-lm(mpg~.-name-displacement+sqrt(displacement),data=Auto)
summary(trans_lm2)
# Adjusted R-squared 82.52%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하지만, cylinders, horsepower, acceleration, sqrt(displacement)는 유의하지 않아보인다. 즉, 제곱근 변환보다는 로그 변환을 취하는 것이 좋다.

#horsepower
plot(Auto$horsepower, Auto$mpg)
plot(log(Auto$horsepower), Auto$mpg)
abline(lm(mpg ~ log(horsepower), data = Auto), lty = 1, col = "red")
plot(sqrt(Auto$horsepower), Auto$mpg)
plot((Auto$horsepower)^2, Auto$mpg)
# 그려진 plot들을 보면, horsepower는 로그 변환을 취하는 것이 좋아보인다.

trans_lm3<-lm(mpg~.-name-horsepower+log(horsepower),data=Auto)
summary(trans_lm3)
# Adjusted R-squared 83.4%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하지만, cylinders 변수는 유의하지 않다 판단된다.

#weight
plot(Auto$weight, Auto$mpg)
plot(log(Auto$weight), Auto$mpg)
abline(lm(mpg ~ log(weight), data = Auto), lty = 1, col = "red")
plot(sqrt(Auto$weight), Auto$mpg)
plot((Auto$weight)^2, Auto$mpg)
# 그려진 plot들을 보면, weight는 로그 변환을 취하는 것이 좋아보인다.

trans_lm4<-lm(mpg~.-name-weight+log(weight),data=Auto)
summary(trans_lm4)
# Adjusted R-squared 84.31%만큼의 설명력을 가진다고 판단할 수 있다. F통계량의 p-value값이 2.2e-16보다 작으므로 유의수준 0.05보다 작아서 모델이 통계적으로 유의하지만, cylinders, horsepower, acceleration 변수는 유의하지 않다 판단된다.

```



## ch3) 14.
### (a)
```{r}
set.seed(1)
x1 = runif(100)
x2 = 0.5 * x1 + rnorm(100)/10
y = 2 + 2 * x1 + 0.3 * x2 + rnorm(100)

###Q) Write out the form of the linear model
#sol)
#y = beta0 + beta1*x1 + beta2*x2 + ε => 2개의 설명변수(x1, x2)가 있는 linear model
#위 문제에서 linear model의 form은 "y = 2 + 2*x1 + 0.3*x2 + ε , ε ~ N(0,1)" 이다.

###Q) What are the regression coefficients?
#sol) 
#회귀계수는 beta0=2, beta1=2, beta2=0.3 임을 알 수 있다.
```

### (b)
```{r}
cor(x1, x2)
cor.test(x1, x2)

par(mfrow = c(1,1))
plot(x1, x2, col="red", pch =20, main="Scatter Plot of x1 and x2")

###Q) x1과 x2의 상관 관계
#sol) 
#x1과 x2의 pearson 상관계수 = 0.8351212 로서 상당히 높은 양의 상관관계를 가지는 것으로 나왔다. 따라서 x1과 x2 사이에 공선성을 의심할 수 있어 보인다.
#(상관계수는 1에 가까울수록 강한 양의 선형관계를 가지므로)
```

### (c)
```{r}
fit <- lm(y ~ x1 + x2)
summary(fit)

###Q) fit a least squares regression to predict y using x1, x2
#sol) 
#least squares regression 적합 결과,
#H0 : 회귀모형은 타당하지 않다 vs  H1 : 회귀모형은 타당하다
#유의확률이 1.164e-05이므로 유의수준 0.05에서 귀무가설을 기각할 수 있다.
#따라서, 유의수준 0.05하에서 위의 회귀모형은 타당하다고 판단된다.
#Multiple-R-squared ==> 회귀모형의 설명력(독립변수의 설명력)은 약 20.88% 정도이다.

#β0 hat = 2.1305, β1 hat = 1.4396, β2 hat = 1.0097

#β0 = 2, β1 = 2, β2 = 0.3 true 값과 비교해보면
#β0와 β0 hat은 비슷하다.
#β1와 β1 hat은 2-1.4396 = 0.5 이상이 차이가 난다.
#β2는 β2 hat은 0.3-1.0097 = 0.7 이상의 차이가 난다.

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x1의 p-value가 0.0487이므로 유의수준 0.05하에서 β1에 대한 귀무가설을 기각할 수 있다. 따라서 유의수준 0.05하에서 β1은 0이 아니라고 할 수 있다.

#H0 : β2 = 0 vs  H1 : β2은 0이 아니다.
#x2의 p-value가 0.3754이므로 유의수준 0.05하에서 β2에 대한 귀무가설을 기각할 수 없다. 따라서 유의수준 0.05하에서 β2는 0이라고 할 수 있다.
```

### (d)
```{r}
fit2 <- lm(y ~ x1)
summary(fit2)

###Q) fit a least squares regression to predict y using only x1
#sol) 
#least squares regression 적합 결과,
#H0 : 회귀모형은 타당하지 않다 vs  H1 : 회귀모형은 타당하다
#유의확률이 2.661e-06이므로 유의수준 0.05에서 귀무가설을 기각할 수 있다.
#따라서, 유의수준 0.05하에서 회귀모형은 타당하다고 판단된다.
#Multiple-R-squared ==> 회귀모형의 설명력(독립변수의 설명력)은 약 20.24% 정도이다.

#β0 hat = 2.1124, β1 hat = 1.9759

#β0 = 2, β1 = 2 true 값과 비교해보면
#β0와 β0 hat은 비슷하다.
#β1와 β1 hat은 비슷하다. x1의 coefficient는 (c)에서와 다른 결과를 보였다.

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x1 p-value가 2.66e-06으로 유의수준 0.05하에서 β1 = 0이라는 귀무가설을 기각할 수 있다. 따라서 유의수준 0.05하에서 β1은 0이 아니라고 할 수 있다.
```

### (e)
```{r}
fit3 <- lm(y ~ x2)
summary(fit3)

###Q) fit a least squares regression to predict y using only x2
#sol) 
#least squares regression 적합 결과,
#H0 : 회귀모형은 타당하지 않다 vs  H1 : 회귀모형은 타당하다
#유의확률이 1.366e-05이므로 유의수준 0.05에서 회귀모형은 통계적으로 타당하다.
#Multiple-R-squared ==> 회귀모형의 설명력(독립변수의 설명력)은 약 17.63% 정도이다.

#β0 hat = 2.3899, β1 hat = 2.8996

#β0 = 2, β1 = 0.3 true 값과 비교해보면
#β0와 β0 hat은 비슷하다.
#β1와 β1 hat은 상당히 큰 차이를 보인다. x2의 coefficient는 (c)에서와 다른 결과를 보였다.

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x2의 p-value가 1.37e-05로 유의수준 0.05하에서 β1 = 0이라는 귀무가설을 기각할 수 있다. 따라서 유의수준 0.05하에서 β1은 0이 아니라고 할 수 있다.
```


### (f)
```{r}
fit$coefficients
fit2$coefficients
fit3$coefficients

###Q) (c)-(e) contradict each other? explain your answer.
#sol) 
#fit2와 fit3에서 x1, x2 두 변수를 모두 이용하여 최소제곱회귀를 적합 했을 때와는 다른 결과가 x2변수에서 보였다. 
#x1 변수만 이용하여 적합한 fit2에서는 x1의 p-value가 매우 작게 나와 x1이 유의하다 판단했다.
#x2 변수만 이용하여 적합한 fit3에서는 유의수준 0.05하에서 유의하지 않던 x2가 유의하다는 결과가 나왔다.
#즉, x2의 회귀계수 유의성 검정에서 모순된 결과를 얻었다는 것을 확인할 수 있다.
#이는 독립변수 x1과 x2 사이에 연관성이 있기 때문에 이러한 결과가 나타는 것으로 보인다. 앞서 (b)에서 확인한 x1과 x2의상관계수 = 0.8351212 로서 상당히 높은 양의 상관관계를 가지는 것을 통해 알 수 있다.

#어떤 한 설명번수를 모형에 제거(or추가)하는 것이 추정된 회귀계수의 크기(or 부호)에 큰 변화를 준 것으로 보아 이들 사이의 공선성을 의심할 수 있다. 
```

### (g)
```{r}
x1 = c(x1, 0.1)
x2 = c(x2, 0.8)
y = c(y, 6)

fit_new <- lm(y ~ x1 + x2)
summary(fit_new)
#least squares regression 적합 결과,
#β0 hat = 2.2267, β1 hat = 0.5394, β2 hat = 2.5146

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x1의 p-value가 0.36458로 유의수준 0.05하에서 귀무가설을 기각할 수가 없다. 따라서 유의수준 0.05하에서 β1은 0이라고 할 수 있다.

#H0 : β2 = 0 vs  H1 : β2은 0이 아니다.
#x2 p-value가 0.00614로 유의수준 0.05하에서 귀무가설을 기각할 수 있다. 따라서 유의수준 0.05하에서 β2은 0이 아니라고 할 수 있다.

#fit_new에서 위의 fit결과와는 다르게 x2의 변수가 유의하다고 나왔다.

fit2_new <- lm(y ~ x1)
summary(fit2_new)
#least squares regression 적합 결과,
#β0 hat = 2.2569, β1 hat = 1.7657

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x1의 p-value가 4.29e-05로 유의수준 0.05하에서 귀무가설 기각할 수 있다. 따라서 유의수준 0.05하에서 β1은 0이 아니라고 할 수 있다.

#x1, x2 두 변수를 모두 이용하여 적합한 fit_new에서는 x1의 회귀계수가 유의수준 0.05하에서 유의하지 않다고 나왔지만,
#x1 변수만을 이용하여 적합한 fit2_new에서는 x1 변수의 회귀계수가 유의수준 0.05하에서 유의하다는 결과가 나왔다.

fit3_new <- lm(y ~ x2)
summary(fit3_new)
#least squares regression 적합 결과,
#β0 hat = 2.3451, β1 hat = 3.1190

#H0 : β1 = 0 vs  H1 : β1은 0이 아니다.
#x2의 p-value가 1.25e-06로 유의수준 0.05하에서 귀무가설 기각할 수 있다. 따라서 유의수준 0.05하에서 β1은 0이 아니라고 할 수 있다.

#x1, x2 두 변수를 모두 이용하여 적합한 fit_new에서는 x2의 회귀계수가 유의수준 0.05하에서 유의하다고 나왔고, x2 변수만을 이용하여 적합한 fit3_new에서 또한 x2 변수의 회귀계수가 유의수준 0.05하에서 유의하다는 결과가 나왔다.


###Q) In each model, is this obs an outlier? A high-leverage point? Both?
par(mfrow=c(1,3))

#x1~x2 
plot(fit_new, which=c(1,5))
#Residuals vs Fitted를 보면 완벽한 수평선 모형은 아니더라도 잔차의 평균이 0에 가까운 선을 보인다. 다만 point 21, 55, 82가 outlier로 보인다.
#Residuals vs Leverage를 보면 point 101가 high leverage point&outlier이다.
plot(x1,x2, main="x2~x1") #(변수들간의 관계확인)
grid()
points(0.1, 0.8, col = "red", type = "p", pch = 15)
abline(v = mean(x1), h = mean(x2), col = c("green", "blue"))


#y~x1
plot(fit2_new, which=c(1,5))
##no high liverage point
#Residuals vs Fitted를 보면 완벽한 수평선 모형은 아니더라도 잔차의 평균이 0에 가까운 선을 보인다. 다만 point 101, 55, 82가 outlier로 보이고 Residuals vs Leverage를 보면 point 101,21,55가 high leverage point로 보이지만 대게 point들이 왼쪽에 모여있지 않고 퍼져있으므로 leverage 인지 판단하기 어렵다. 그래서 다음과 같이 influence()함수를 이용하여 확인해보았다.
plot(x1, y, main="y~x1")
grid()
abline(coef(fit2_new))
points(0.1, 6, col = "red", type = "p", pch = 15)
abline(v = mean(x1), h = mean(y), col = c("green", "blue"))

#outlier, high leverage 기준
#high leverage : diagonal elements of hat matrix ==> hii > 3p'/n 
#good leverage points : leverage가 높지만 residual이 작은 데이터
#bad leverage points = outlier : leverage도 높지만 residual도 큰 데이터
par(mfrow=c(1,2))
influ2 <- influence(fit2_new)
idx2 <- influ2$hat > 3*sum(influ2$hat)/101
plot(influ2$hat, main="Leverage")
lines(influ2$hat, type="h")
plot(y~x1, main="y~x1")
abline(fit2_new, col=rgb(0.1,0.6,0.1,0.5), lwd=3)
grid()
points(x1[idx2], y[idx2], col=rgb(0.8,0.2,0.2,0.5), pch=16, cex=5)
#위 결과, high leverage에 대한 point가 그림에 나오지 않는다. 따라서 이 기준(hii > 3p'/n)에서는 high leverage가 없다고 판단된다. 

#y~x2
par(mfrow=c(1,3))
plot(fit3_new, which=c(1,5))
##high leverage point
#Residuals vs Fitted를 보면 완벽한 수평선 모형은 아니더라도 잔차의 평균이 0에 가까운 선을 보인다. 다만 point 21,55,82가 outlier로 보인다.
#Residuals vs Leverage를 보면 point 22와 55는 low leverage면서 outlier, 101은 high leverage point로 보인다.
plot(x2, y, main="y~x2")
grid()
abline(coef(fit3_new))
points(0.8, 6, col = "red", type = "p", pch = 15)
abline(v = mean(x2), h = mean(y), col = c("green", "blue"))

par(mfrow=c(1,2))
influ3 <- influence(fit3_new)
plot(influ3$hat, main="Leverage")
idx3 <- influ3$hat > 3*sum(influ3$hat)/101
lines(influ3$hat, type="h")
plot(y~x2, main="y~x2")
abline(fit3_new, col=rgb(0.1,0.6,0.1,0.5), lwd=3)
grid()
points(x2[idx3], y[idx3], col=rgb(0.8,0.2,0.2,0.5), pch=16, cex=5)
#y~x1과 다르게 우리가 plot(x2,y)에 그린 것과 influence를 이용해 확인한 high leverage가 그림에 나오는 것을 확인할 수 있다.

#각 모델에서 전반적으로 101번째 관측치가 high liverage & outlier로 보인다.


```



## ch4) 11.
### (a)
```{r}
data(Auto)
mpg01 <- ifelse(Auto$mpg > median(Auto$mpg), 1, 0)
auto <- data.frame(Auto, mpg01)
summary(auto)
str(auto)
```

### (b)
```{r}
#help("pairs") pairs문서에 오픈되어 있는 함수 이용 (산점도와 상관계수를 같이 보기위해)
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

###Q) investigate the association between mpg01 and the other features
#sol)
pairs(auto, lower.panel = panel.smooth, upper.panel = panel.cor)
#mpg01과 다른 feature들 간의 산점도와 상관계수를 본 결과, mpg01변수와 cylinders, displacement, horsepower, weight 변수들의 상관계수가 높다는 것을 파악할 수 있었다. 따라서 위 변수들이 mpg01 변수를 예측하는데 도움을 주는 predictors 들이 될 것이라 생각한다.

#mpg01과의 boxplot으로 좀 더 살펴보면,
par(mfrow = c(2,3))
boxplot(cylinders ~ mpg01, data = auto)
boxplot(displacement ~ mpg01, data = auto)
boxplot(horsepower ~ mpg01, data = auto)
boxplot(weight ~ mpg01, data = auto)
boxplot(acceleration ~ mpg01, data = auto)
boxplot(year ~ mpg01, data = auto)
#그림을 보면, 전반적으로 mpg01에 따라 차이가 있어 보이며 cylinders, displacement, horseposer, weight는 상대적으로 acceleration, year에 비해서 mpg01에 따라 차이가 큰 것 것으로 보인다.
#따라서 mpg01변수와 cylinders, displacement, horsepower, weight 변수들 사이에 연관성이 있어 보이므로 위 변수들이 mpg01 변수를 예측하는데 유용할 것으로 판단된다.
 
```

### (c)
```{r}
set.seed(1004)
id <- sample(1:nrow(auto), nrow(auto)*0.7) #train_data 0.7, test_data 0.3
train_data <- auto[id,] #training data
test_data <- auto[-id,] #test data
mpg01_train <- auto$mpg01[id] # y train
mpg01_test <- auto$mpg01[-id] # y test

print(paste0('train_data: ', nrow(train_data)))
print(paste0('test_data: ', nrow(test_data)))
print(paste0('mpg01_train: ', length(mpg01_train)))
print(paste0('mpg01_test: ', length(mpg01_test)))

###Q) Split the data into a training set and a test set
#sol) 
#무작위로 선택한 데이터의 70%를 training data로 분할하고 나머지 30%를 test data로 분할하였다.
```

### (f)
```{r}
fit_glm <- glm(mpg01 ~ cylinders + weight + displacement + horsepower, data = train_data, family = 'binomial')
summary(fit_glm)

###Q) logistic regression on the training data, What is the test error of the model obtained?
#sol) 
#(b)에서 가장 관련있어 보인 cylinders, displacement, horsepower, weight 변수들을 가지고 logistic regression을 fit한 결과, 유의수준 0.05 하에서 p_value가 0.05보다 작은 변수는 weight과 horsepower이며, 이 두 변수가 통계적으로 유의한 결과를 가진다.

#train data로 만든 모델로 test data를 가지고 예측해 보면
fit.pred.prob <- predict(fit_glm, test_data, type = "response")
result <- table(round(fit.pred.prob), test_data$mpg01)  #round(fit.pred.prob) <==> ifelse(fit.pred.prob > 0.5, 1, 0)
result
# round(fit.pred.prob) ==> mpg01은 0과 1, 위 예측값은 확률이므로 잘 예측되었는지 비교하기 위해 반올림으로 0과 1로 만들어주었다.
#0을 0으로 예측한것이 42개, 1을 1로 예측한것이 63개로 나왔다.

error_rate <- (result[1,2]+result[2,1])/nrow(test_data) 
error_rate*100
#오분류율 = (6 + 7) / 118 = 0.1101695
#로지스틱 모델에서의 오분류율은 11.01695%이다.

```

### (g)
```{r}
train_x <- train_data[,2:5]
train_y <- mpg01_train
test_x <- test_data[,2:5]
test_y <- mpg01_test

fit_knn <- knn(train_x, test_x, cl=train_y, k = 1)
result <- table(fit_knn,test_y)
result
error_rate <- (result[1,2]+result[2,1])/nrow(test_x)
error_rate*100 
#오분류율 = (10 + 9) / 118 = 0.1610169

#best k를 찾기 위해 반복문을 만들어 수행시켜 보았다.
store_error <- numeric(nrow(test_x))
for (i in 1:nrow(test_x)) {
  fit_knn <- knn(train_x, test_x, train_y, k = i)
  result <- table(fit_knn,test_y)

  error_rate <- (result[1,2]+result[2,1])/nrow(test_x)
  store_error[i] <- error_rate
}

plot(store_error, type = "l")
idx <- which(store_error == min(store_error))
points(x = idx, store_error[idx], pch = 15, col = "red")
idx #이 때가 오분류율이 최저인 군집수가 된다.

###Q) KNN on the training data, with several values of K, What test errors do you obtain? Which value of K seems to perform the best on this data set?
#sol) 
#(b)에서 가장 관련있어 보인 cylinders, displacement, horsepower, weight 변수들을 가지고 knn 결과,
#k=1, test error = 16.1%
store_error[idx]*100 #min(store_error)
#k=idx인 경우에서 8.5% 정도의 최소의 오분류율을 가짐을 알 수 있다.
#k가 idx인 경우에서 knn을 잘 수행한다고 판단된다.

```